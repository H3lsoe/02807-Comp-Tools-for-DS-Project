{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2c272587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "import time\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c8712bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) == \"Notebooks\":\n",
    "    project_root = os.path.dirname(cwd)\n",
    "else:\n",
    "    project_root = cwd\n",
    "path = os.path.join(project_root, \"data\", \"Airbnb_DK_Processed_Data.csv\")\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0bf8279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_log'] = np.log1p(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9252fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "# ------- Combining less common property types into 'Other' and encoding\n",
    "common = df['property_type'].value_counts()[lambda x: x >= 50].index\n",
    "df['property_type'] = df['property_type'].where(df['property_type'].isin(common), 'Other')\n",
    "df['property_type_encoded'] = le.fit_transform(df['property_type'])\n",
    "# ------- Encoding neighbourhood_cleansed\n",
    "df['neighbourhood_cleansed_encoded'] = le.fit_transform(df['neighbourhood_cleansed'])\n",
    "# ------- Converting room_type to binary feature (Entire home/private room and similar)\n",
    "df['is_entire_place'] = (df['room_type'] == 'Entire home/apt').astype(int)\n",
    "# ------- Combining less common bathroom info into 'Other' and encoding\n",
    "common = df['bathrooms_text'].value_counts()[lambda x: x >= 100].index\n",
    "df['bathrooms_text'] = df['bathrooms_text'].where(df['bathrooms_text'].isin(common), 'Other')\n",
    "df['bathrooms_text_encoded'] = le.fit_transform(df['bathrooms_text'])\n",
    "# ------- Capping minimum_nights at 10, removes unnecessary outliers\n",
    "df['minimum_nights_capped'] = df['minimum_nights'].clip(upper=10)\n",
    "# ------- Capping number_of_reviews at 25, removes unnecessary outliers\n",
    "df['number_of_reviews_capped'] = df['number_of_reviews'].clip(upper=25)\n",
    "# ------- Converting some features to binary feature\n",
    "df['instant_bookable'] = (df['instant_bookable'] == 't').astype(int)\n",
    "df['host_is_superhost'] = (df['host_is_superhost'] == 't').astype(int)\n",
    "# ------- Encoding host_response_time\n",
    "df['host_response_time_encoded'] = le.fit_transform(df['host_response_time'])\n",
    "# ------- Dont use estimated_occupancy_l365d and estimated_revenue_l365d due to data leakag\n",
    "# ------- Combining less common bathroom info into 'Other' and encoding\n",
    "common = df['host_verifications'].value_counts()[lambda x: x >= 100].index\n",
    "df['host_verifications'] = df['host_verifications'].where(df['host_verifications'].isin(common), 'Other')\n",
    "df['host_verifications_encoded'] = le.fit_transform(df['host_verifications'])\n",
    "# ------- Creating amenities count features\n",
    "df['amenities_list'] = df['amenities'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "df['amenities_count'] = df['amenities_list'].apply(len)\n",
    "keywords = ['Wifi', 'Pool', 'Hot tub', 'Air conditioning', \n",
    "            'Free parking', 'Kitchen', 'Washer', 'Dryer', \n",
    "            'Heating', 'TV', 'Pets allowed']\n",
    "df['count_high_value_amenities'] = df['amenities_list'].apply(lambda lst: sum(any(kw.lower() in a.lower() for a in lst) for kw in keywords))\n",
    "#\n",
    "coords = df[['latitude', 'longitude']]\n",
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "df['location_cluster'] = kmeans.fit_predict(coords)\n",
    "# ------- Ignore name, description, comments for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2b6c5be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Running hyperparameter search...\n",
      "Fitting 3 folds for each of 250 candidates, totalling 750 fits\n",
      "‚úÖ Search done in 39.8s\n",
      "Best parameters: {'colsample_bytree': 0.8105610643744453, 'gamma': 0.29263580870213274, 'learning_rate': 0.026325996406117914, 'max_depth': 8, 'min_child_weight': 7, 'n_estimators': 823, 'reg_alpha': 0.07977234005659417, 'reg_lambda': 2.2435671331844036, 'subsample': 0.6876855949432177}\n",
      "üèÅ Final RMSE on unscaled price: 534.811\n",
      "\n",
      "üîù Top 10 important features:\n",
      "                           feature  importance\n",
      "2                  is_entire_place    0.497974\n",
      "3                     accommodates    0.141874\n",
      "4                         bedrooms    0.130240\n",
      "18              dist_to_raadhus_km    0.030242\n",
      "5           bathrooms_text_encoded    0.024924\n",
      "0            property_type_encoded    0.019022\n",
      "1   neighbourhood_cleansed_encoded    0.016145\n",
      "8                        longitude    0.015160\n",
      "19                location_cluster    0.014743\n",
      "12                instant_bookable    0.014009\n"
     ]
    }
   ],
   "source": [
    "feature_for_model = ['property_type_encoded', 'neighbourhood_cleansed_encoded', 'is_entire_place', 'accommodates', 'bedrooms', 'bathrooms_text_encoded', 'minimum_nights_capped', 'latitude', 'longitude', 'review_scores_rating', 'review_scores_cleanliness', 'number_of_reviews_capped', 'instant_bookable', 'host_is_superhost', 'host_response_time_encoded', 'host_verifications_encoded', 'amenities_count', 'count_high_value_amenities', 'dist_to_raadhus_km', 'location_cluster']\n",
    "\n",
    "# ===============================\n",
    "# 1Ô∏è‚É£ Prepare data\n",
    "# ===============================\n",
    "X = df[feature_for_model]\n",
    "y = df['price_log']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 2Ô∏è‚É£ Define base model\n",
    "# ===============================\n",
    "xgb_base = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    tree_method='hist',          # fast on large datasets\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 3Ô∏è‚É£ Define hyperparameter search space\n",
    "# ===============================\n",
    "param_dist = {\n",
    "    'n_estimators': randint(300, 1200),\n",
    "    'learning_rate': uniform(0.01, 0.2),       # 0.01‚Äì0.21\n",
    "    'max_depth': randint(3, 10),\n",
    "    'subsample': uniform(0.6, 0.4),            # 0.6‚Äì1.0\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': uniform(0, 0.4),\n",
    "    'reg_lambda': uniform(0.5, 2.0),\n",
    "    'reg_alpha': uniform(0, 0.5)\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# 4Ô∏è‚É£ Randomized Search (CV)\n",
    "# ===============================\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=250,                          # 50 random combos (good tradeoff)\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,                               # 3-fold CV\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"üîç Running hyperparameter search...\")\n",
    "start = time.time()\n",
    "search.fit(X_train, y_train)\n",
    "print(f\"‚úÖ Search done in {time.time()-start:.1f}s\")\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "\n",
    "# ===============================\n",
    "# 5Ô∏è‚É£ Refit best model with early stopping\n",
    "# ===============================\n",
    "best_params = search.best_params_\n",
    "best_model = XGBRegressor(\n",
    "    **best_params,\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    tree_method='hist',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 6Ô∏è‚É£ Evaluate\n",
    "# ===============================\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))\n",
    "print(f\"üèÅ Final RMSE on unscaled price: {rmse:.3f}\")\n",
    "\n",
    "# ===============================\n",
    "# 7Ô∏è‚É£ Feature importance\n",
    "# ===============================\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüîù Top 10 important features:\")\n",
    "print(importance.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7f405d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 320.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "print(f\"MAE: {mae:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "504da40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23570202552965924"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae / np.expm1(y_test).mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
