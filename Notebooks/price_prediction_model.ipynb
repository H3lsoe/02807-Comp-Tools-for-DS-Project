{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477a724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import time\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# ===========================================================\n",
    "# 0Ô∏è‚É£ LOAD DATA\n",
    "# ===========================================================\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) == \"Notebooks\":\n",
    "    project_root = os.path.dirname(cwd)\n",
    "else:\n",
    "    project_root = cwd\n",
    "\n",
    "path = os.path.join(project_root, \"data\", \"Airbnb_DK_Processed_Data.csv\")\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Keep a pristine copy if you want\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8872ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11579 entries, 0 to 11578\n",
      "Data columns (total 52 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              11579 non-null  int64  \n",
      " 1   name                            11579 non-null  object \n",
      " 2   description                     11353 non-null  object \n",
      " 3   host_id                         11579 non-null  int64  \n",
      " 4   host_name                       11243 non-null  object \n",
      " 5   host_since                      11239 non-null  object \n",
      " 6   host_location                   9406 non-null   object \n",
      " 7   host_response_time              10120 non-null  object \n",
      " 8   host_response_rate              10120 non-null  object \n",
      " 9   host_acceptance_rate            10852 non-null  object \n",
      " 10  host_is_superhost               11490 non-null  object \n",
      " 11  host_listings_count             11239 non-null  float64\n",
      " 12  host_total_listings_count       11239 non-null  float64\n",
      " 13  host_verifications              11239 non-null  object \n",
      " 14  host_identity_verified          11239 non-null  object \n",
      " 15  neighbourhood_cleansed          11579 non-null  object \n",
      " 16  latitude                        11579 non-null  float64\n",
      " 17  longitude                       11579 non-null  float64\n",
      " 18  property_type                   11579 non-null  object \n",
      " 19  room_type                       11579 non-null  object \n",
      " 20  accommodates                    11579 non-null  int64  \n",
      " 21  bathrooms_text                  11576 non-null  object \n",
      " 22  bedrooms                        11578 non-null  float64\n",
      " 23  amenities                       11579 non-null  object \n",
      " 24  price                           11579 non-null  float64\n",
      " 25  minimum_nights                  11579 non-null  int64  \n",
      " 26  maximum_nights                  11579 non-null  int64  \n",
      " 27  has_availability                11579 non-null  object \n",
      " 28  availability_30                 11579 non-null  int64  \n",
      " 29  availability_60                 11579 non-null  int64  \n",
      " 30  availability_90                 11579 non-null  int64  \n",
      " 31  availability_365                11579 non-null  int64  \n",
      " 32  number_of_reviews               11579 non-null  int64  \n",
      " 33  number_of_reviews_ltm           11579 non-null  int64  \n",
      " 34  availability_eoy                11579 non-null  int64  \n",
      " 35  number_of_reviews_ly            11579 non-null  int64  \n",
      " 36  estimated_occupancy_l365d       11579 non-null  int64  \n",
      " 37  estimated_revenue_l365d         11579 non-null  float64\n",
      " 38  first_review                    11579 non-null  object \n",
      " 39  last_review                     11579 non-null  object \n",
      " 40  review_scores_rating            11579 non-null  float64\n",
      " 41  review_scores_accuracy          11579 non-null  float64\n",
      " 42  review_scores_cleanliness       11579 non-null  float64\n",
      " 43  review_scores_checkin           11579 non-null  float64\n",
      " 44  review_scores_communication     11579 non-null  float64\n",
      " 45  review_scores_location          11578 non-null  float64\n",
      " 46  review_scores_value             11579 non-null  float64\n",
      " 47  instant_bookable                11579 non-null  object \n",
      " 48  calculated_host_listings_count  11579 non-null  int64  \n",
      " 49  reviews_per_month               11579 non-null  float64\n",
      " 50  comments                        11579 non-null  object \n",
      " 51  dist_to_raadhus_km              11579 non-null  float64\n",
      "dtypes: float64(16), int64(15), object(21)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef0780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "üîÅ Fold 1/5\n",
      "======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benyla/miniconda3/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MAE:  274.060\n",
      "Fold 1 RMSE: 458.998\n",
      "\n",
      "======================\n",
      "üîÅ Fold 2/5\n",
      "======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benyla/miniconda3/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 MAE:  273.738\n",
      "Fold 2 RMSE: 469.989\n",
      "\n",
      "======================\n",
      "üîÅ Fold 3/5\n",
      "======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benyla/miniconda3/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 MAE:  292.152\n",
      "Fold 3 RMSE: 539.499\n",
      "\n",
      "======================\n",
      "üîÅ Fold 4/5\n",
      "======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benyla/miniconda3/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 MAE:  291.634\n",
      "Fold 4 RMSE: 516.743\n",
      "\n",
      "======================\n",
      "üîÅ Fold 5/5\n",
      "======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benyla/miniconda3/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 MAE:  339.461\n",
      "Fold 5 RMSE: 1706.760\n",
      "\n",
      "======================\n",
      "üìä OOF MAE:  294.205\n",
      "üìä OOF RMSE: 883.375\n",
      "======================\n",
      "\n",
      "üíæ Saved id + OOF predictions to:\n",
      "/Users/benyla/Documents/GitHub/02807-Comp-Tools-for-DS-Project/data/Airbnb_OOF_Predictions.csv\n",
      "üíæ Saved full dataset with OOF preds to:\n",
      "/Users/benyla/Documents/GitHub/02807-Comp-Tools-for-DS-Project/data/Airbnb_DK_Processed_Data_with_oof.csv\n"
     ]
    }
   ],
   "source": [
    "# Target in log space\n",
    "df[\"price_log\"] = np.log1p(df[\"price\"])\n",
    "\n",
    "# ===========================================================\n",
    "# 1Ô∏è‚É£ GLOBAL FEATURE ENGINEERING (NO TARGET USED HERE)\n",
    "# ===========================================================\n",
    "\n",
    "# --- Bathrooms parsing ---\n",
    "def parse_bathroom_text(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan, np.nan\n",
    "    s = str(x).lower()\n",
    "    nums = re.findall(r'([\\d\\.]+)', s)\n",
    "    num = float(nums[0]) if nums else np.nan\n",
    "    shared = 1 if 'shared' in s else 0\n",
    "    return num, shared\n",
    "\n",
    "df[[\"bathrooms_num\", \"bathrooms_shared\"]] = df[\"bathrooms_text\"].apply(\n",
    "    lambda x: pd.Series(parse_bathroom_text(x))\n",
    ")\n",
    "\n",
    "# --- Capped features ---\n",
    "df[\"minimum_nights_capped\"] = df[\"minimum_nights\"].clip(upper=10)\n",
    "df[\"number_of_reviews_capped\"] = df[\"number_of_reviews\"].clip(upper=25)\n",
    "\n",
    "# --- Binary flags ---\n",
    "df[\"instant_bookable_bin\"] = (df[\"instant_bookable\"] == \"t\").astype(int)\n",
    "df[\"host_is_superhost_bin\"] = (df[\"host_is_superhost\"] == \"t\").astype(int)\n",
    "\n",
    "# --- Review presence & missingness ---\n",
    "df[\"has_reviews\"] = (df[\"number_of_reviews\"] > 0).astype(int)\n",
    "df[\"review_scores_rating_missing\"] = df[\"review_scores_rating\"].isna().astype(int)\n",
    "\n",
    "# --- Dates & time-based features ---\n",
    "for col in [\"host_since\", \"first_review\", \"last_review\"]:\n",
    "    df[col + \"_dt\"] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "ref_date = df[\"last_review_dt\"].max()\n",
    "\n",
    "df[\"host_since_days\"] = (ref_date - df[\"host_since_dt\"]).dt.days\n",
    "df[\"days_since_first_review\"] = (ref_date - df[\"first_review_dt\"]).dt.days\n",
    "df[\"days_since_last_review\"] = (ref_date - df[\"last_review_dt\"]).dt.days\n",
    "\n",
    "# --- Comments features & sentiment ---\n",
    "df[\"comments\"] = df[\"comments\"].fillna(\"\")\n",
    "df[\"comments_length\"] = df[\"comments\"].str.len()\n",
    "df[\"comments_word_count\"] = df[\"comments\"].apply(lambda x: len(x.split()))\n",
    "df[\"comments_exclamation\"] = df[\"comments\"].str.count(\"!\")\n",
    "df[\"comments_sentiment\"] = df[\"comments\"].apply(\n",
    "    lambda x: sia.polarity_scores(x)[\"compound\"]\n",
    ")\n",
    "\n",
    "# --- Amenities basic parsing ---\n",
    "df[\"amenities_list\"] = df[\"amenities\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    ")\n",
    "df[\"amenities_count\"] = df[\"amenities_list\"].apply(len)\n",
    "\n",
    "important_amenities = [\n",
    "    \"Wifi\", \"Kitchen\", \"Heating\", \"Air conditioning\", \"Washer\", \"Dryer\",\n",
    "    \"TV\", \"Hot tub\", \"Pool\", \"Pets allowed\", \"Free parking\"\n",
    "]\n",
    "\n",
    "def count_high_value_amenities(lst):\n",
    "    s = [str(a).lower() for a in lst]\n",
    "    return sum(any(kw.lower() in a for a in s) for kw in important_amenities)\n",
    "\n",
    "df[\"count_high_value_amenities\"] = df[\"amenities_list\"].apply(count_high_value_amenities)\n",
    "\n",
    "# ===========================================================\n",
    "# 2Ô∏è‚É£ OUT-OF-FOLD SETUP\n",
    "# ===========================================================\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "oof_predictions = np.zeros(len(df))  # on ORIGINAL price scale\n",
    "\n",
    "def safe_col_name(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"[^0-9a-z]+\", \"_\", s)\n",
    "    return s.strip(\"_\")\n",
    "\n",
    "# For sanity checks later\n",
    "all_feature_names = None\n",
    "\n",
    "# ===========================================================\n",
    "# 3Ô∏è‚É£ FOLD LOOP (NO LEAKAGE)\n",
    "# ===========================================================\n",
    "fold = 1\n",
    "for train_idx, valid_idx in kf.split(df):\n",
    "\n",
    "    print(f\"\\n======================\")\n",
    "    print(f\"üîÅ Fold {fold}/{n_splits}\")\n",
    "    print(f\"======================\")\n",
    "\n",
    "    # Fresh copies per fold (we never write back into df inside loop)\n",
    "    df_train = df.iloc[train_idx].copy()\n",
    "    df_valid = df.iloc[valid_idx].copy()\n",
    "\n",
    "    y_train = df_train[\"price_log\"]\n",
    "    y_valid = df_valid[\"price_log\"]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3.1 KMeans on train coords only\n",
    "    # -------------------------------\n",
    "    kmeans = KMeans(n_clusters=100, random_state=42)\n",
    "    df_train[\"location_cluster\"] = kmeans.fit_predict(\n",
    "        df_train[[\"latitude\", \"longitude\"]]\n",
    "    )\n",
    "    df_valid[\"location_cluster\"] = kmeans.predict(\n",
    "        df_valid[[\"latitude\", \"longitude\"]]\n",
    "    )\n",
    "\n",
    "    # Radian coords\n",
    "    df_train[\"lat_rad\"] = np.radians(df_train[\"latitude\"])\n",
    "    df_train[\"lon_rad\"] = np.radians(df_train[\"longitude\"])\n",
    "    df_valid[\"lat_rad\"] = np.radians(df_valid[\"latitude\"])\n",
    "    df_valid[\"lon_rad\"] = np.radians(df_valid[\"longitude\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3.2 TF-IDF on name (train only)\n",
    "    # -------------------------------\n",
    "    tfidf = TfidfVectorizer(max_features=80)\n",
    "    name_train = tfidf.fit_transform(df_train[\"name\"].fillna(\"\"))\n",
    "    name_valid = tfidf.transform(df_valid[\"name\"].fillna(\"\"))\n",
    "\n",
    "    tfidf_cols = [f\"name_tfidf_{i}\" for i in range(name_train.shape[1])]\n",
    "\n",
    "    df_train = pd.concat(\n",
    "        [df_train,\n",
    "         pd.DataFrame(name_train.toarray(), columns=tfidf_cols, index=df_train.index)],\n",
    "        axis=1\n",
    "    )\n",
    "    df_valid = pd.concat(\n",
    "        [df_valid,\n",
    "         pd.DataFrame(name_valid.toarray(), columns=tfidf_cols, index=df_valid.index)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3.3 Target Encoding (train only)\n",
    "    # -------------------------------\n",
    "    te_cols = [\n",
    "        \"property_type\",\n",
    "        \"neighbourhood_cleansed\",\n",
    "        \"host_response_time\",\n",
    "        \"host_verifications\",\n",
    "        \"bathrooms_text\",\n",
    "        \"room_type\",\n",
    "    ]\n",
    "\n",
    "    te = TargetEncoder(cols=te_cols, smoothing=5.0)\n",
    "    te.fit(df_train[te_cols], y_train)\n",
    "\n",
    "    df_train_te = te.transform(df_train[te_cols]).add_suffix(\"_te\")\n",
    "    df_valid_te = te.transform(df_valid[te_cols]).add_suffix(\"_te\")\n",
    "\n",
    "    df_train = pd.concat([df_train, df_train_te], axis=1)\n",
    "    df_valid = pd.concat([df_valid, df_valid_te], axis=1)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3.4 Build numeric feature matrix\n",
    "    # -------------------------------\n",
    "    drop_cols = [\n",
    "        \"id\",\n",
    "        \"price\",\n",
    "        \"price_log\",\n",
    "        \"name\",\n",
    "        \"description\",\n",
    "        \"comments\",\n",
    "        \"amenities\",\n",
    "        \"amenities_list\",\n",
    "        \"property_type\",\n",
    "        \"neighbourhood_cleansed\",\n",
    "        \"host_response_time\",\n",
    "        \"host_verifications\",\n",
    "        \"bathrooms_text\",\n",
    "        \"room_type\",\n",
    "        \"first_review\",\n",
    "        \"last_review\",\n",
    "        \"first_review_dt\",\n",
    "        \"last_review_dt\",\n",
    "        \"host_since\",\n",
    "        \"host_since_dt\",\n",
    "        \"estimated_occupancy_l365d\",\n",
    "        \"estimated_revenue_l365d\",\n",
    "    ]\n",
    "\n",
    "    df_train_model = df_train.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    df_valid_model = df_valid.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "    feature_cols = df_train_model.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    # Optionally check all folds use same features\n",
    "    if all_feature_names is None:\n",
    "        all_feature_names = feature_cols\n",
    "    else:\n",
    "        if feature_cols != all_feature_names:\n",
    "            raise ValueError(\"Feature mismatch between folds ‚Äì check your pipeline!\")\n",
    "\n",
    "    X_train = df_train_model[feature_cols]\n",
    "    X_valid = df_valid_model[feature_cols]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3.5 Train XGBoost (no HP search here)\n",
    "    # -------------------------------\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        early_stopping_rounds=50,\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        objective=\"reg:squarederror\",\n",
    "        eval_metric=\"rmse\",\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    preds_log = model.predict(X_valid)\n",
    "    preds_price = np.expm1(preds_log)  # back to original scale\n",
    "\n",
    "    # Store OOF preds for this fold\n",
    "    oof_predictions[valid_idx] = preds_price\n",
    "\n",
    "    # Optional: fold metrics\n",
    "    fold_mae = mean_absolute_error(np.expm1(y_valid), preds_price)\n",
    "    fold_rmse = np.sqrt(mean_squared_error(np.expm1(y_valid), preds_price))\n",
    "    print(f\"Fold {fold} MAE:  {fold_mae:.3f}\")\n",
    "    print(f\"Fold {fold} RMSE: {fold_rmse:.3f}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# ===========================================================\n",
    "# 4Ô∏è‚É£ GLOBAL OOF EVALUATION (NO LEAKAGE)\n",
    "# ===========================================================\n",
    "y_true = df[\"price\"].values\n",
    "\n",
    "oof_mae = mean_absolute_error(y_true, oof_predictions)\n",
    "oof_rmse = np.sqrt(mean_squared_error(y_true, oof_predictions))\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(f\"üìä OOF MAE:  {oof_mae:.3f}\")\n",
    "print(f\"üìä OOF RMSE: {oof_rmse:.3f}\")\n",
    "print(\"======================\")\n",
    "\n",
    "# ===========================================================\n",
    "# 5Ô∏è‚É£ SAVE PREDICTIONS\n",
    "# ===========================================================\n",
    "# a) Just id + prediction (for later merge)\n",
    "oof_df = pd.DataFrame({\n",
    "    \"id\": df[\"id\"],\n",
    "    \"price_oof_pred\": oof_predictions\n",
    "})\n",
    "pred_path = os.path.join(project_root, \"data\", \"Airbnb_OOF_Predictions.csv\")\n",
    "oof_df.to_csv(pred_path, index=False)\n",
    "print(f\"\\nüíæ Saved id + OOF predictions to:\\n{pred_path}\")\n",
    "\n",
    "# b) Full dataset with new column\n",
    "df_with_pred = df_original.copy()\n",
    "df_with_pred[\"price_oof_pred\"] = oof_predictions\n",
    "full_path = os.path.join(project_root, \"data\", \"Airbnb_DK_Processed_Data.csv\")\n",
    "df_with_pred.to_csv(full_path, index=False)\n",
    "print(f\"üíæ Saved full dataset with OOF preds to:\\n{full_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
